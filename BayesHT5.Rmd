---
title: "HT5-Bayes"
author: "Andres Quinto, Mirka Monzon, Oscar De Leon"
date: "14/03/2022"
output: 
  html_document:
    code_folding: hide
    word_document: default
    pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Hoja de Trabajo No. 5:

Como continuación a las hojas de trabajo anteriores, trabajaremos repartiendo los datos en un 70% para entrenamiento y 30% para prueba y se clasificará los precios de las casas en 3, que es lo que se busca predecir.

### 1. Use los mismos conjuntos de entrenamiento y prueba que utilizó en las dos hojas anteriores. 

```{r warning=FALSE, unload=TRUE}
#Librerias a utilizar
library(e1071)
library(caret)
library(magrittr)
library(plyr)
library(dplyr)
library(cluster)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
library(readr)
library(ppclust)
library(randomForest)
library(ggplot2)
library(broom)
library(ggpubr)
library(corrplot)
library(mctest)
library(Amelia)
library(caretEnsemble)
library(psych)
library(mice)
library(GGally)
library(rpart)
#base de datos a utilzar
datos <- read.csv("train.csv")
datosCasas <- datos[,-c(1,7)]
```

###  2. Elabore un modelo de bayes ingenuo (naive bayes) utilizando el conjunto de entrenamiento y explique los resultados a los que llega. El experimento debe ser reproducible por lo que debe fijar que los conjuntos de entrenamiento y prueba sean los mismos siempre que se ejecute el código. 

### 3. El modelo debe ser de clasificación, use la variable categórica que hizo con el precio de las casas (barata, media y cara) como variable respuesta. 

```{r, echo=FALSE}

getmode <- function(v){
  v=v[nchar(as.character(v))>0]
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}
for (cols in colnames(datosCasas)) {
  if (cols %in% names(datosCasas[,sapply(datosCasas, is.numeric)])) {
    datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), is.na(!!rlang::sym(cols)), mean(!!rlang::sym(cols), na.rm=TRUE)))
  }
  else {
    datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), !!rlang::sym(cols)=="", getmode(!!rlang::sym(cols))))
  }
}
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-30]
datosCasas <- datosCasas[,-24]
datosCasas <- datosCasas[,-50]
#View(datosCasas)
porciento <- 70/100
#variable que clasifica las casas
datosCasas$clasificacion <- ifelse(datosCasas$SalePrice <= 251000, "Economicas", ifelse(datosCasas$SalePrice <= 538000, "Intermedias", ifelse(datosCasas$SalePrice <= 755000, "Caras")))
datosCasas$y <- factor(datosCasas$clasificacion)
set.seed(123)
trainRowsNumber<-sample(nrow(datosCasas),porciento*nrow(datosCasas))
train<-datosCasas[trainRowsNumber,]
test<-datosCasas[-trainRowsNumber,]
#modelo de naivebayes
modelo<-naiveBayes(train$y~., data=train)
modelo
```
Con esto puede observarse que las probabilidades a priori obtenidas son: caras 0.4897%, economicas 85.01% e intermedias 14.50%.

Es decir, la mayoría de casas se encuentra en un rango de precio de venta económico, seguido por las casas con un precio de venta intermedio y por último se encuentran aquellas con un precio de venta elevado.
